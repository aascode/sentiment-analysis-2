{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hCJ7VTq1r-B",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# **Sentiment Analysis**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrfoCSVi1uU_",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# **1. Installation**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfMMl1bb1x_2",
        "colab_type": "text"
      },
      "source": [
        "## i. Generating a reponse\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soQns5KH0mNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import logging\n",
        "from psutil import virtual_memory"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwXk46ge1zYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "ram_gb = virtual_memory().total / 1e9"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqYgi67z1zgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_response = {\n",
        "    'error': None,\n",
        "    'TF version': '',\n",
        "    'COLAB': None,\n",
        "    'GPU': False,\n",
        "    'ram_gb': ''\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvNt2AJ51znJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898317e6-b24d-49b2-f20a-5ad8f71b0d86"
      },
      "source": [
        "try:\n",
        "    # drive\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "    # updating tensorflow version\n",
        "    %tensorflow_version 2.x\n",
        "\n",
        "    # tensorflow-gpu\n",
        "    !pip install tensorflow-gpu # !pip install tensorflow_text # I could use BERT\n",
        "    \n",
        "    # NLP (nltk, stanza, spacy)\n",
        "    !pip install nltk \n",
        "    !pip install stanza\n",
        "    !pip install spacy\n",
        "    !spacy download en_core_web_sm # sm md lg\n",
        "    !python -m spacy download en\n",
        "except OSError as error:\n",
        "    # debugging error\n",
        "    response['error'] = logging.debug('You are not using your specify version of TensorFlow')\n",
        "    IN_COLAB = False\n",
        "\n",
        "    # install requirements\n",
        "    !pip install -r '../requirements.txt'\n",
        "finally:\n",
        "    tf_response['COLAB'] = IN_COLAB\n",
        "    \n",
        "    # Importing tensroflow core\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Activation, Embedding, Bidirectional\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    \n",
        "    # GPU and RAM response\n",
        "    if tf.config.list_physical_devices('GPU'):\n",
        "        GPU = True\n",
        "        tf_response['GPU'] = GPU\n",
        "        tf_response['TF_version'] = tf.__version__\n",
        "        \n",
        "        if tf_response['COLAB'] == True:\n",
        "            if gpu_info.find('failed') >= 0:\n",
        "                print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator')\n",
        "                print('Re-execute this cell.')\n",
        "            else:\n",
        "                print(gpu_info)\n",
        "            \n",
        "            if ram_gb < 20:\n",
        "                print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type menu\"')\n",
        "                print('Select high-RAM in the runtime shape dropdown')\n",
        "                print('Re-execute this cell')\n",
        "                tf_response['ram_gb'] = 'low-RAM runtime'\n",
        "            else:\n",
        "                tf_response['ram_gb'] = 'high-RAM runtime'\n",
        "            print('\\nRuntime {:.2f} GB of available RAM\\n'.format(ram_gb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (50.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: stanza in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.6.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (50.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye99iKv617qQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFNjTuvU1_C_",
        "colab_type": "text"
      },
      "source": [
        "## ii. Importing modules\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIh873U819qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data analysis\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import re\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator # to create a Word Cloud\n",
        "from PIL import Image # Pillow with WordCloud to image manipulation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lhfhNt72CLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T82WGVnN2EwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stanza NLP\n",
        "import stanza\n",
        "\n",
        "stanza.download('en', package='ewt', processors='tokenize,mwt,pos,lemma', verbose=True)\n",
        "stNLP = stanza.Pipeline(processors='tokenize,mwt,pos,lemma',\n",
        "                      lang='en',\n",
        "                      use_gpu=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9236VgMj2Gwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing stanza\n",
        "doc = stNLP('Barack Obama was born in Hawai.')\n",
        "print('\\n')\n",
        "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4QpRgR02IDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Spacy NLP\n",
        "import spacy\n",
        "spNLP = spacy.load('en_core_web_sm')\n",
        "spNLP.max_length = 103950039 # or higher\n",
        "# spacy.prefer_gpu() #will not work with stanza"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6iiQVT42Jo3",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "# **2. Hyperparameters**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUv__06r2LOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 30\n",
        "vocab_size = 5000\n",
        "embedding_dim = 64\n",
        "max_lenght = 200\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = '<OOV>'\n",
        "training_portion = .8\n",
        "\n",
        "FILE = 'datasets/categories_dataset.csv'\n",
        "main_labels = ['confident', 'unconfident', 'pos_hp', 'neg_hp', 'interested', 'uninterested', 'happy', 'unhappy', 'friendly', 'unfriendly']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO32c_pD2NzO",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# **3. Lemmatization**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb6Wbv0U2OeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lemmatizion\n",
        "# stanza\n",
        "def stanza_lemma(text):\n",
        "    doc = stNLP(text)\n",
        "    return ' '.join([word.lemma for sent in doc.sentences for word in sent.words])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdtBcgKB2PaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nltk_lemma(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatizer.lemmatize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yfg8TVR2SL_",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# **4. Load dataset**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUCh3RCa2VS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_clean_dataset():\n",
        "    !mkdir -p datasets\n",
        "    !wget -nc https://raw.githubusercontent.com/Y4rd13/sentiment-analysis/master/datasets/results/categories_dataset.csv -P datasets\n",
        "    df = pd.read_csv('./datasets/categories_dataset.csv', encoding='utf-8')\n",
        "    x, y = df.word, df.category\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kleN4LtF2-bg",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# **5. Prepare dataset**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y-Y8HxI3E7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_dataset(test_size=0.2, validation_size=0.2):\n",
        "    print('preparing the dataset...\\n')\n",
        "    \n",
        "    # load dataset\n",
        "    # split dataset (as string into panda.core.series.Serie object)\n",
        "    x, y = load_clean_dataset()\n",
        "    \n",
        "    # create/split train, validation and test\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n",
        "    x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=validation_size)\n",
        "\n",
        "    # pandas.core.series.Series to numpy array\n",
        "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "    x_validation, y_validation =  np.array(x_validation), np.array(y_validation)\n",
        "    x_test, y_test = np.array(x_test), np.array(y_test)\n",
        "\n",
        "    return (x_train, y_train), (x_validation, y_validation), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qEs4mw33Vg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test prepare_dataset function\n",
        "(x_train, y_train), (x_validation, y_validation), (x_test, y_test) = prepare_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KxC1h6O3nW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "def prepare_dataset_testing():\n",
        "    print('preparing the dataset...\\n')\n",
        "           \n",
        "    # test with csv module\n",
        "    labels, texts = [], [] \n",
        "    with open('./datasets/categories_dataset.csv', 'r', encoding='utf-8') as csvfile:\n",
        "        reader = csv.reader(csvfile, delimiter=',')\n",
        "        next(reader)\n",
        "        for row in reader:\n",
        "            print(row)\n",
        "            labels.append(row[0])\n",
        "            text = row[1]\n",
        "            for i in STOPWORDS:\n",
        "                token = ' ' + i + ' '\n",
        "                text = text.replace(token, ' ')\n",
        "                text = text.replace(' ', ' ')\n",
        "            texts.append(text)\n",
        "\n",
        "    # split\n",
        "    train_size = int(len(texts) * training_portion)\n",
        "\n",
        "    train_texts = texts[:train_size]\n",
        "    train_labels = labels[:train_size]\n",
        "\n",
        "    validation_texts = texts[train_size:]\n",
        "    validation_labels = labels[train_size:]\n",
        "\n",
        "    # tokenizer\n",
        "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "\n",
        "    tokenizer.fit_on_texts(train_texts)\n",
        "    word_index = tokenizer.word_index\n",
        "\n",
        "    # text to sequences: triain_texts\n",
        "    train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "\n",
        "    # padding and truncating sequences: train_seq\n",
        "    train_padded = pad_sequences(sequences=train_sequences, maxlen=max_lenght,\n",
        "                                 padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "    # same process: validation_texts\n",
        "    valdiation_sequences = tokenizer.texts_to_sequences(validation_texts)\n",
        "    validation_padded = pad_sequences(valdiation_sequences, maxlen=max_lenght, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "    # tokenize & sequences to train and validation LABELS\n",
        "    label_tokenizer = Tokenizer()\n",
        "    label_tokenizer.fit_on_texts(labels)\n",
        "\n",
        "    training_label_seq = np.array(label_tokenizer.texts_to_sequences(train_labels))\n",
        "    validation_label_seq = np.array(label_tokenizer.texts_to_sequences(validation_labels))\n",
        "\n",
        "    print(label_tokenizer.word_index)\n",
        "\n",
        "    return train_padded, training_label_seq, validation_padded, validation_label_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQEwk09b4PD_",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# **4. Build model**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD18U_yE4SOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(learning_rate=0.0001, opt='adam', loss='categorical_crossentropy'):\n",
        "    print('building the model...\\n')\n",
        "\n",
        "    # model\n",
        "    model = Sequential()\n",
        "\n",
        "    # layers\n",
        "    model.add(Embedding(vocab_size, embedding_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Bidirectional(LSTM(embedding_dim)))\n",
        "\n",
        "    # softmax output layer\n",
        "    model.add(tf.keras.layers.Dense(units=2, # 10 \n",
        "                                    activation='softmax'))\n",
        "\n",
        "    # optimizer & loss\n",
        "    opt = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "    loss='sparse_categorical_crossentropy'\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss=loss,\n",
        "                  metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf048l554Uug",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# **6. Train model** \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-pVOZYb4T3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, x_train, y_train, x_validation, y_validation,\n",
        "          epochs, batch_size=32, patience=5, \n",
        "          verbose=2, monitor='accuracy'):\n",
        "    \n",
        "    print('training...\\n')\n",
        "\n",
        "    # callback\n",
        "    early_callback = tf.keras.callbacks.EarlyStopping(monitor=monitor, # also try 'val_loss'\n",
        "                                                      verbose=1, mode='auto', restore_best_weights=True,\n",
        "                                                      min_delta=1e-3, patience=patience)\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=batch_size, epochs=epochs, verbose=verbose,\n",
        "                        validation_data=(x_validation, y_validation), # x_test, y_test\n",
        "                        callbacks=[early_callback])\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy3DyM-b4XPg",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# **7. Plotting history**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssFJ3CIe4YPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history_(history):\n",
        "    fitModel_dict = history.history\n",
        "    acc = fitModel_dict['accuracy']\n",
        "    val_acc = fitModel_dict['val_accuracy']\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "    \n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
        "    plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.ylim((0.5, 1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def plot_history(history, string):\n",
        "    fitModel_dict = history.history\n",
        "    plt.plot(fitModel_dict[string])\n",
        "    plt.plot/fitModel_dict['val_' + string]\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_' + string])\n",
        "    plt.show()\n",
        "\n",
        "# test\n",
        "#plot_history(history, 'accuracy')\n",
        "#plot_history(history, 'loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FN5osTo4aC4",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# **8. Main**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAb369Lh4ajo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    # prepare the dataset\n",
        "    #x_train, y_train, x_validation, y_validation, x_test, y_test = prepare_dataset()\n",
        "    train_padded, training_label_seq, validation_padded, validation_label_seq = prepare_dataset_testing()\n",
        "\n",
        "    # build the model\n",
        "    model = build_model()\n",
        "\n",
        "    # train the model\n",
        "    history = train(model=model, x_train=train_padded, y_train=training_label_seq,\n",
        "                    x_validation=validation_padded, y_validation=validation_label_seq,\n",
        "                    epochs=EPOCHS, verbose=1)\n",
        "\n",
        "    # plot the training\n",
        "    plot_history(history)\n",
        "\n",
        "    # evaluate the model\n",
        "    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "    print('\\nTest:\\nLoss: {}\\nAccuracy: {}').format(loss, accuracy * 100)\n",
        "\n",
        "    # save the model\n",
        "    model.save(model.h5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02Lry1jA4b4w",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# **9. __name__ == \"__main__\"**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Krj1rBH4dOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}